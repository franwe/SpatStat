---
title: "Assignment Block B"
author: "Bianca Neubert and Franziska Wehrmann"
output: pdf_document
header-includes:
   - \usepackage{ dsfont }
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(maps)         ## Projections
library(maptools)     ## Data management
library(sp)           ## Data management
library(spdep)        ## Spatial autocorrelation
library(gstat)        ## Geostatistics
library(splancs)      ## Kernel Density
library(spatstat)     ## Geostatistics
library(pgirmess)     ## Spatial autocorrelation
library(RColorBrewer) ## Visualization
library(rgdal)
library(classInt)     ## Class intervals
library(spgwr)        ## GWR
library(raster)
knitr::opts_chunk$set(fig.width=3, fig.height = 2.5)
```

# Theory

## Markov random fields
Let Y denote a GMRF with mean vector \(\mu\) and precision matrix \(Q\) of dimension \(n \in \mathbb{N}\).

i) To show: 
\begin{align*}
Y_i \vert Y_{-i} \sim \mathcal{N} \left( \mu_i - \frac{1}{q_{ii}} \sum_{j \in \text{ne}(i)} q_{ij} (y_j - \mu_j) , \frac{1}{q_{ii}} \right)
\end{align*}

**Proof**: Since \(Y\) is a GMRF with expectation \(\mu\) and precision matrix \(Q\), we have for the conditional density of \(Y_i \vert Y_{-i}\)
$$\pi(y_i \vert y_{-i}) = \pi(y_i \vert y_{\text{ne}(i)})$$
where \(y_{\text{ne}(i)}\) denotes the vector with indices in \(\text{ne}(i)\). Because the MRF is Gaussian, we have further for every \(A \subset \{1,...,n\}\)
$$Y_A \sim \mathcal{N}(\mu_A, Q_A^{-1})$$
where \(Y_A = (Y_i)_{i \in A}\), \(\mu_A = (\mu_i)_{i \in A}\) and \(Q_A = (q_{ij})_{i,j \in A}\) for the entries \(q_{ij}\) of \(Q\).

Combining this, we get for the density of \(Y_i \vert Y_{-i}\), since \(Y_{\text{ne}(i)}\) is also normally distributed and hence has strictly positive density, that
\begin{align*}
\pi(y_i \vert y_{-i}) &= \frac{\pi(y_{\{i\} \cup \text{ne}(i)})}{\pi(y_{\text{ne}(i)})}\\
&\propto \exp \left\{ - \frac{1}{2} (y_{\{i\} \cup \text{ne}(i)} - \mu_{\{i\} \cup \text{ne}(i)})^{T} Q_{\{i\} \cup \text{ne}(i)} (y_{\{i\} \cup \text{ne}(i)} - \mu_{\{i\} \cup \text{ne}(i)}) \right.\\
& \ \ \ \ \left.+\frac{1}{2} (y_{\text{ne}(i)} - \mu_{ \text{ne}(i)})^{T} Q_{\text{ne}(i)}(y_{\text{ne}(i)} - \mu_{\text{ne}(i)})   \right\} \\
& = \exp \left\{  -  \frac{1}{2} \left[ q_{ii}y_{ii}^2 + 2 \sum_{j \in \text{ne}(i)} y_i q_{ij} y_j + q_{ii} \mu_i^2 + 2 \sum_{j \in \text{ne}(i)} \mu_i q_{ij} \mu_j \right. \right. \\
 & \ \ \ \ \left. \left. - 2 q_{ii} \mu_i y_i - 2 \sum_{j \in \text{ne}(i)} \mu_i q_{ij} y_j  - 2 \sum_{j \in \text{ne}(i)} y_i q_{ij} \mu_j \right] \right\} \\
 & = \exp \left\{ - \frac{q_{ii}}{2}  \left[ (y_i - \mu_i)^2 + \frac{2}{q_{ii}}(y_i - \mu_i)\sum_{j \in \text{ne}(i)}q_{ij}(y_j - \mu_j) \right] \right\} \\
 & \propto \exp \left\{ - \frac{q_{ii}}{2} \left[  y_i - \mu_i + \frac{1}{q_{ii}} \sum_{j \in \text{ne}(i)} q_{ij} (y_j - \mu_j)  \right]^2 \right\}
\end{align*}
which is the kernel of a normal distribution with the given expecation and variance.


iii) To show: \(\mathbb{C}\text{or} [Y_i, Y_j \vert Y_{-ij}] = - \frac{q_{ij}}{\sqrt{q_{ii}q_{jj}}}\)

Proof:

## Local charcteristics
Suppose \(S\) is a finite set equipped with a symmetry relation \(\sim\). For count outcomes, a specification commonly used in disease mapping is the *auto-Poisson* model where
\begin{align*}
\pi(y_i\vert y_{S\setminus i}) = \exp(-\mu_i)\frac{\mu_i^{y_i}}{y_i \!}\\
\log(\mu_i) = - \sum_{j\in\text{ne}(i)} y_j \ i \not= j
\end{align*}
for \(y \in \mathbb{N}_0\), \(i \in S\). Determine the canonical potential with respect to \(a = 0\).

# Computation

## Guerry's data on social morals
This task is based on Guerry's data on moral statistics including aggregated numbers of suicide (`suicids`). Let us first import and inspect the data.
```{r, warning=F}
guerry <- readOGR("guerry/Guerry.shp")
```
We see that the variables are stored in form of strings, so we first change the class to integer of the three variables of interest in this assignment: `Suicids`, `Wealth` and `Clergy`
```{r, warning=F}
guerry$Suicids <- as.integer(guerry$Suicids)
guerry$Wealth <- as.integer(guerry$Wealth)
guerry$Clergy <- as.integer(guerry$Clergy)
```

Using `spplot` we can get a first impression on the spatial distribution of these variables.


```{r, fig.width=3, fig.height=3, echo= FALSE}
spplot(guerry, "Wealth", main="Wealth")
spplot(guerry, "Clergy", main="Clergy")
spplot(guerry, "Suicids", main="Suicides")
```

Specify a (non-spatial) regression model of `Wealth` and `Clergy` on `Suicids`.
```{r}
reg <- lm(Suicids ~ Wealth + Clergy, data=guerry)
summary(reg)
```
We can see, that in this the coefficients of Clergy and Wealth are not significant which at first does not indicate a relationship between these and Suicides. This model does not explain the variation in Suicides very well (e.g. Multiple R-squared = 0.011).

We can plot the residuals:
First, we fix color palette once for all plots of this type. This way it is easier to compare the results later.

```{r}
m = 98661.66  # maximum residual of (lm, car, sar, sdm)
breaks = round(c(-m, -0.4*m, -0.1*m, 0.1*m, 0.4*m, m), digits=0)
res.palette <- colorRampPalette(c("red","orange","white", "lightgreen","green"), space = "rgb")
pal <- res.palette(5)
```

Now we can plot the residuals of the linear model.

```{r, echo = F, fig.width=9, fig.height=5}
res <- reg$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey",pretty=T)
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),title="Residuals from Linear Model",ncol=5)
```

To test for autocorrelation in the data, we can use Moran's I and Geary's C. For this, we need to specify  a neighborhood structure in a matrix. 
```{r, fig.width=4, fig.height=4}
xy <- coordinates(guerry)
W_cont_el <- poly2nb(guerry, queen=FALSE)
W_cont_el_mat <- nb2listw(W_cont_el, style="B", zero.policy=TRUE)
plot(W_cont_el_mat, coords=xy, cex=0.1, col="gray")
```

For the Moran's I ad Geary's C we get the following results
```{r, echo=FALSE}
moran.test(guerry$Suicids, listw=W_cont_el_mat, zero.policy=T)
geary.test(guerry$Suicids, listw=W_cont_el_mat, zero.policy=T)
```

The Moran's I test statistic and its expectation are both close to zero (0.074 and -0.011). However, the Moran's I test statistic is larger than the expectation which is an indication for a positive autocorrelation. If we look the given p-value we can reject the null of no autocorrelation for a 0.1-niveau, but not for a 0.05-niveau. On the other hand, Geary's C is close to 1 and the p-value with 0.197 suggests that the null of no autocorrelation can not be rejeceted for a 0.1-niveau. To sum this up, there seems to be very little global autocorrelation in the data, if there is any at all. 


#### CAR
Let us compute a CAR model.
```{r}
car.out <- spdep::spautolm(Suicids ~ Wealth + Clergy, data=guerry,
                           listw=W_cont_el_mat, family="CAR")
mod.car <- fitted(car.out)
summary(car.out)
```

Again, the coefficients for Wealth and Clergy are not significant. The plot of the residuals:

```{r, echo = F, fig.width=9, fig.height=5}
res <- car.out$fit$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey",pretty=T)
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),
       title="Residuals from CAR Model",ncol=5)
```


#### SAR
Now, the same for SAR
```{r}
mod.sar <- lagsarlm(Suicids ~ Wealth + Clergy, data=guerry,
                    listw=W_cont_el_mat, zero.policy=T, tol.solve=1e-12)
summary(mod.sar)
```

Again, the coefficients for Wealth and Clergy are not significant.The plot of the residuals:

```{r, echo = F, fig.width=9, fig.height=5}
res <- mod.sar$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey",pretty=T)
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),
       title="Residuals from SAR Model",ncol=5)
```

#### SDM
And SDM
```{r}
mod.sdm <- lagsarlm(Suicids ~ Wealth + Clergy, data=guerry, listw=W_cont_el_mat, 
                    zero.policy=T, type="mixed", tol.solve=1e-12)
summary(mod.sdm)
```

```{r, echo = F, fig.width=9, fig.height=5}
res <- mod.sdm$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey")
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),title="Residuals from SDM Model",ncol=5)
```

## Comparison

- In all regression models it is obvious that the most extreme values got mitigated, which is especially noticable since the scale of the original data goes up to 16.000 Suicides, whereas the regressed data only reaches 9.000
- SDM seems more precise than SAR (Pattern of predicted values and plot of residuals), which is not surprising since it (SDM) has the additional term of spatially lagged covariates over the SAR model.
- The Linear Regression has pretty huge residuals, especially around the extreme Suicid-Values, which is not surprising since it does not take any spatial relationships into account. 
- CAR?

```{r, echo=FALSE, fig.width=5, fig.height=5}
Original.plot.values <- spplot(guerry, "Suicids", main="Guerry Data")
guerry$CAR <- car.out$fit$fitted.values
CAR.plot.values <- spplot(guerry, "CAR", main="CAR")
guerry$SAR <- mod.sar$fitted.values
SAR.plot.values <- spplot(guerry, "SAR", main="SAR")
guerry$SDM <- mod.sdm$fitted.values
SDM.plot.values <- spplot(guerry, "SDM", main="SDM")
require(gridExtra)
grid.arrange(Original.plot.values, 
             CAR.plot.values, 
             SAR.plot.values, 
             SDM.plot.values, ncol = 2)
```


```{r, echo = F, fig.width=9, fig.height=4}
res <- reg$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey",pretty=T)
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),title="Residuals from Linear Model",ncol=5)
```

```{r, echo = F, fig.width=9, fig.height=4}
res <- car.out$fit$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey",pretty=T)
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),
       title="Residuals from CAR Model",ncol=5)
```

```{r, echo = F, fig.width=9, fig.height=4}
res <- mod.sar$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey",pretty=T)
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),
       title="Residuals from SAR Model",ncol=5)
```

```{r, echo = F, fig.width=9, fig.height=4}
res <- mod.sdm$residuals
classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=breaks, rtimes = 1)
cols <- findColours(classes_fx,pal)
plot(guerry,col=cols, border="grey")
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),title="Residuals from SDM Model",ncol=5)
```
